{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/twitter-airline-sentiment/Tweets.csv\n/kaggle/input/twitter-airline-sentiment/database.sqlite\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic packages\nimport pandas as pd \nimport numpy as np\nimport re\nimport collections\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n# Packages for data preparation\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\n# Packages for modeling\nfrom keras import models\nfrom keras import layers\nfrom keras import regularizers\nNB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\nNB_START_EPOCHS = 20  # Number of epochs we usually start to train with\nBATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent\nMAX_LEN = 20  # Maximum number of words in a sequence","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def deep_model(model, X_train, y_train, X_valid, y_valid):\n    '''\n    Function to train a multi-class model. The number of epochs and \n    batch_size are set by the constants at the top of the\n    notebook. \n    \n    Parameters:\n        model : model with the chosen architecture\n        X_train : training features\n        y_train : training target\n        X_valid : validation features\n        Y_valid : validation target\n    Output:\n        model training history\n    '''\n    model.compile(optimizer='rmsprop'\n                  , loss='categorical_crossentropy'\n                  , metrics=['accuracy'])\n    \n    history = model.fit(X_train\n                       , y_train\n                       , epochs=NB_START_EPOCHS\n                       , batch_size=BATCH_SIZE\n                       , validation_data=(X_valid, y_valid)\n                       , verbose=0)\n    return history\ndef eval_metric(model, history, metric_name):\n    '''\n    Function to evaluate a trained model on a chosen metric. \n    Training and validation metric are plotted in a\n    line chart for each epoch.\n    \n    Parameters:\n        history : model training history\n        metric_name : loss or accuracy\n    Output:\n        line chart with epochs of x-axis and metric on\n        y-axis\n    '''\n    metric = history.history[metric_name]\n    val_metric = history.history['val_' + metric_name]\n    e = range(1, NB_START_EPOCHS + 1)\n    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n    plt.xlabel('Epoch number')\n    plt.ylabel(metric_name)\n    plt.title('Comparing training and validation ' + metric_name + ' for ' + model.name)\n    plt.legend()\n    plt.show()\ndef test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n    '''\n    Function to test the model on new data after training it\n    on the full training data with the optimal number of epochs.\n    \n    Parameters:\n        model : trained model\n        X_train : training features\n        y_train : training target\n        X_test : test features\n        y_test : test target\n        epochs : optimal number of epochs\n    Output:\n        test accuracy and test loss\n    '''\n    model.fit(X_train\n              , y_train\n              , epochs=epoch_stop\n              , batch_size=BATCH_SIZE\n              , verbose=0)\n    results = model.evaluate(X_test, y_test)\n    print()\n    print('Test accuracy: {0:.2f}%'.format(results[1]*100))\n    return results\n    \ndef remove_stopwords(input_text):\n    '''\n    Function to remove English stopwords from a Pandas Series.\n    \n    Parameters:\n        input_text : text to clean\n    Output:\n        cleaned Pandas Series \n    '''\n    stopwords_list = stopwords.words('english')\n    # Some words which might indicate a certain sentiment are kept via a whitelist\n    whitelist = [\"n't\", \"not\", \"no\"]\n    words = input_text.split() \n    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n    return \" \".join(clean_words) \n    \ndef remove_mentions(input_text):\n    '''\n    Function to remove mentions, preceded by @, in a Pandas Series\n    \n    Parameters:\n        input_text : text to clean\n    Output:\n        cleaned Pandas Series \n    '''\n    return re.sub(r'@\\w+', '', input_text)\ndef compare_models_by_metric(model_1, model_2, model_hist_1, model_hist_2, metric):\n    '''\n    Function to compare a metric between two models \n    \n    Parameters:\n        model_hist_1 : training history of model 1\n        model_hist_2 : training history of model 2\n        metrix : metric to compare, loss, acc, val_loss or val_acc\n        \n    Output:\n        plot of metrics of both models\n    '''\n    metric_model_1 = model_hist_1.history[metric]\n    metric_model_2 = model_hist_2.history[metric]\n    e = range(1, NB_START_EPOCHS + 1)\n    \n    metrics_dict = {\n        'acc' : 'Training Accuracy',\n        'loss' : 'Training Loss',\n        'val_acc' : 'Validation accuracy',\n        'val_loss' : 'Validation loss'\n    }\n    \n    metric_label = metrics_dict[metric]\n    plt.plot(e, metric_model_1, 'bo', label=model_1.name)\n    plt.plot(e, metric_model_2, 'b', label=model_2.name)\n    plt.xlabel('Epoch number')\n    plt.ylabel(metric_label)\n    plt.title('Comparing ' + metric_label + ' between models')\n    plt.legend()\n    plt.show()\n    \ndef optimal_epoch(model_hist):\n    '''\n    Function to return the epoch number where the validation loss is\n    at its minimum\n    \n    Parameters:\n        model_hist : training history of model\n    Output:\n        epoch number with minimum validation loss\n    '''\n    min_epoch = np.argmin(model_hist.history['val_loss']) + 1\n    print(\"Minimum validation loss reached in epoch {}\".format(min_epoch))\n    return min_epoch","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/twitter-airline-sentiment/Tweets.csv')\ndf = df.reindex(np.random.permutation(df.index))  \ndf = df[['text', 'airline_sentiment']]\ndf.text = df.text.apply(remove_stopwords).apply(remove_mentions)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.text, df.airline_sentiment, test_size=0.1, random_state=37)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk = Tokenizer(num_words=NB_WORDS,\n               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{\"}~\\t\\n',\n               lower=True,\n               char_level=False,\n               split=' ')\ntk.fit_on_texts(X_train)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_oh = tk.texts_to_matrix(X_train, mode='binary')\nX_test_oh = tk.texts_to_matrix(X_test, mode='binary')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ny_train_le = le.fit_transform(y_train)\ny_test_le = le.transform(y_test)\ny_train_oh = to_categorical(y_train_le)\ny_test_oh = to_categorical(y_test_le)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(X_train_oh, y_train_oh, test_size=0.1, random_state=37)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model = models.Sequential()\nreg_model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(NB_WORDS,)))\nreg_model.add(layers.Dropout(0.5))\nreg_model.add(layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\nreg_model.add(layers.Dropout(0.5))\nreg_model.add(layers.Dense(3, activation='softmax'))\nreg_history = deep_model(reg_model, X_train_rest, y_train_rest, X_valid, y_valid)\nreg_min = optimal_epoch(reg_history)","execution_count":11,"outputs":[{"output_type":"stream","text":"Minimum validation loss reached in epoch 8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_results = test_model(reg_model, X_train_oh, y_train_oh, X_test_oh, y_test_oh, reg_min)","execution_count":13,"outputs":[{"output_type":"stream","text":"46/46 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.8019\n\nTest accuracy: 80.19%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reg and Dropout did better than each of them singularly","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}